{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'/Users/loki/Documents/work/Personal/learnings/rag-cookbook-langchain/techniques/retriever/aiaun.pdf'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'creator'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'LaTeX with hyperref'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'moddate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-04-10T21:11:43+00:00'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'subject'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'trapped'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/False'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'keywords'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'producer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'pdfTeX-1.40.25'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'page_label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'6'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'creationdate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-04-10T21:11:43+00:00'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'ptex.fullbanner'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">6.3.5'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">lengths longer than the ones encountered\\nduring training. 4 Why Self-Attention\\nIn this section we compare various</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">zn), with xi, zi ∈ Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">our use of self-attention we\\nconsider three desiderata. One is the total computational complexity per layer. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">operations required. The third is the path length between long-range dependencies in the network. Learning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the easier it is to learn long-range dependencies [12]. Hence we also compare\\nthe maximum path length between any </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">two input and output positions in networks composed of the\\ndifferent layer types. As noted in Table 1, a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">are faster than recurrent layers when the sequence\\n6'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'/Users/loki/Documents/work/Personal/learnings/rag-cookbook-langchain/techniques/retriever/aiaun.pdf'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'creator'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'LaTeX with hyperref'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'moddate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-04-10T21:11:43+00:00'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'subject'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'trapped'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/False'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'keywords'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'producer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'pdfTeX-1.40.25'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'page_label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'6'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'creationdate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-04-10T21:11:43+00:00'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'ptex.fullbanner'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">6.3.5'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention. Layer Type Complexity</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">per Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O(n2 · d) O(1) O(1)\\nRecurrent O(n · d2) O(n) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">O(n)\\nConvolutional O(k · n · d2) O(1) O(logk(n))\\nSelf-Attention (restricted) O(r · n · d) O(1) O(n/r)\\n3.5 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Positional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of the\\norder of the sequence, we must inject some information about the relative or absolute position of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the two can be summed. There are many choices of positional encodings,\\nlearned and fixed [9]. In this work, we use</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sine and cosine functions of different frequencies:\\nP E(pos,2i) = sin(pos/100002i/dmodel )\\nP E(pos,2i+1) = </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cos(pos/100002i/dmodel )\\nwhere pos is the position and i is the dimension. That is, each dimension of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">positions, since for any fixed offset k, P Epos+k can be represented as a linear function of\\nP Epos. We also </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">experimented with using learned positional embeddings [9] instead, and found that the two\\nversions produced nearly</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">identical results (see Table 3 row (E)).'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'/Users/loki/Documents/work/Personal/learnings/rag-cookbook-langchain/techniques/retriever/aiaun.pdf'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'creator'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'LaTeX with hyperref'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'moddate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-04-10T21:11:43+00:00'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'subject'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'trapped'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/False'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'keywords'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'producer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'pdfTeX-1.40.25'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'page_label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'3'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'creationdate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-04-10T21:11:43+00:00'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'ptex.fullbanner'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">6.3.5'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The first is a multi-head self-attention mechanism, and the second is a simple, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sub-layers, followed by layer normalization [ 1].'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'page'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "            \u001b[32m'author'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "            \u001b[32m'source'\u001b[0m: \n",
       "\u001b[32m'/Users/loki/Documents/work/Personal/learnings/rag-cookbook-langchain/techniques/retriever/aiaun.pdf'\u001b[0m,\n",
       "            \u001b[32m'creator'\u001b[0m: \u001b[32m'LaTeX with hyperref'\u001b[0m,\n",
       "            \u001b[32m'moddate'\u001b[0m: \u001b[32m'2024-04-10T21:11:43+00:00'\u001b[0m,\n",
       "            \u001b[32m'subject'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "            \u001b[32m'trapped'\u001b[0m: \u001b[32m'/False'\u001b[0m,\n",
       "            \u001b[32m'keywords'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "            \u001b[32m'producer'\u001b[0m: \u001b[32m'pdfTeX-1.40.25'\u001b[0m,\n",
       "            \u001b[32m'page_label'\u001b[0m: \u001b[32m'6'\u001b[0m,\n",
       "            \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m15\u001b[0m,\n",
       "            \u001b[32m'creationdate'\u001b[0m: \u001b[32m'2024-04-10T21:11:43+00:00'\u001b[0m,\n",
       "            \u001b[32m'ptex.fullbanner'\u001b[0m: \u001b[32m'This is pdfTeX, Version 3.141592653-2.6-1.40.25 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mTeX Live 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m kpathsea version \u001b[0m\n",
       "\u001b[32m6.3.5'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence \u001b[0m\n",
       "\u001b[32mlengths longer than the ones encountered\\nduring training. 4 Why Self-Attention\\nIn this section we compare various\u001b[0m\n",
       "\u001b[32maspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one \u001b[0m\n",
       "\u001b[32mvariable-length sequence of symbol representations\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx1, ..., xn\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to another sequence of equal length \u001b[0m\u001b[32m(\u001b[0m\u001b[32mz1, ..., \u001b[0m\n",
       "\u001b[32mzn\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, with xi, zi ∈ Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating \u001b[0m\n",
       "\u001b[32mour use of self-attention we\\nconsider three desiderata. One is the total computational complexity per layer. \u001b[0m\n",
       "\u001b[32mAnother is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential \u001b[0m\n",
       "\u001b[32moperations required. The third is the path length between long-range dependencies in the network. Learning \u001b[0m\n",
       "\u001b[32mlong-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting \u001b[0m\n",
       "\u001b[32mthe\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse \u001b[0m\n",
       "\u001b[32min the network. The shorter these paths between any combination of positions in the input\\nand output sequences, \u001b[0m\n",
       "\u001b[32mthe easier it is to learn long-range dependencies \u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. Hence we also compare\\nthe maximum path length between any \u001b[0m\n",
       "\u001b[32mtwo input and output positions in networks composed of the\\ndifferent layer types. As noted in Table 1, a \u001b[0m\n",
       "\u001b[32mself-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a \u001b[0m\n",
       "\u001b[32mrecurrent layer requires O\u001b[0m\u001b[32m(\u001b[0m\u001b[32mn\u001b[0m\u001b[32m)\u001b[0m\u001b[32m sequential operations. In terms of\\ncomputational complexity, self-attention layers \u001b[0m\n",
       "\u001b[32mare faster than recurrent layers when the sequence\\n6'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'page'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "            \u001b[32m'author'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "            \u001b[32m'source'\u001b[0m: \n",
       "\u001b[32m'/Users/loki/Documents/work/Personal/learnings/rag-cookbook-langchain/techniques/retriever/aiaun.pdf'\u001b[0m,\n",
       "            \u001b[32m'creator'\u001b[0m: \u001b[32m'LaTeX with hyperref'\u001b[0m,\n",
       "            \u001b[32m'moddate'\u001b[0m: \u001b[32m'2024-04-10T21:11:43+00:00'\u001b[0m,\n",
       "            \u001b[32m'subject'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "            \u001b[32m'trapped'\u001b[0m: \u001b[32m'/False'\u001b[0m,\n",
       "            \u001b[32m'keywords'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "            \u001b[32m'producer'\u001b[0m: \u001b[32m'pdfTeX-1.40.25'\u001b[0m,\n",
       "            \u001b[32m'page_label'\u001b[0m: \u001b[32m'6'\u001b[0m,\n",
       "            \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m15\u001b[0m,\n",
       "            \u001b[32m'creationdate'\u001b[0m: \u001b[32m'2024-04-10T21:11:43+00:00'\u001b[0m,\n",
       "            \u001b[32m'ptex.fullbanner'\u001b[0m: \u001b[32m'This is pdfTeX, Version 3.141592653-2.6-1.40.25 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mTeX Live 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m kpathsea version \u001b[0m\n",
       "\u001b[32m6.3.5'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential \u001b[0m\n",
       "\u001b[32moperations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the \u001b[0m\n",
       "\u001b[32mkernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention. Layer Type Complexity\u001b[0m\n",
       "\u001b[32mper Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O\u001b[0m\u001b[32m(\u001b[0m\u001b[32mn2 · d\u001b[0m\u001b[32m)\u001b[0m\u001b[32m O\u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m O\u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nRecurrent O\u001b[0m\u001b[32m(\u001b[0m\u001b[32mn · d2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m O\u001b[0m\u001b[32m(\u001b[0m\u001b[32mn\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mO\u001b[0m\u001b[32m(\u001b[0m\u001b[32mn\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nConvolutional O\u001b[0m\u001b[32m(\u001b[0m\u001b[32mk · n · d2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m O\u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m O\u001b[0m\u001b[32m(\u001b[0m\u001b[32mlogk\u001b[0m\u001b[32m(\u001b[0m\u001b[32mn\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nSelf-Attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mrestricted\u001b[0m\u001b[32m)\u001b[0m\u001b[32m O\u001b[0m\u001b[32m(\u001b[0m\u001b[32mr · n · d\u001b[0m\u001b[32m)\u001b[0m\u001b[32m O\u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m O\u001b[0m\u001b[32m(\u001b[0m\u001b[32mn/r\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n3.5 \u001b[0m\n",
       "\u001b[32mPositional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use \u001b[0m\n",
       "\u001b[32mof the\\norder of the sequence, we must inject some information about the relative or absolute position of \u001b[0m\n",
       "\u001b[32mthe\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of \u001b[0m\n",
       "\u001b[32mthe encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that\u001b[0m\n",
       "\u001b[32mthe two can be summed. There are many choices of positional encodings,\\nlearned and fixed \u001b[0m\u001b[32m[\u001b[0m\u001b[32m9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. In this work, we use\u001b[0m\n",
       "\u001b[32msine and cosine functions of different frequencies:\\nP E\u001b[0m\u001b[32m(\u001b[0m\u001b[32mpos,2i\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = sin\u001b[0m\u001b[32m(\u001b[0m\u001b[32mpos/100002i/dmodel \u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nP E\u001b[0m\u001b[32m(\u001b[0m\u001b[32mpos,2i+1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = \u001b[0m\n",
       "\u001b[32mcos\u001b[0m\u001b[32m(\u001b[0m\u001b[32mpos/100002i/dmodel \u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nwhere pos is the position and i is the dimension. That is, each dimension of the \u001b[0m\n",
       "\u001b[32mpositional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π.\u001b[0m\n",
       "\u001b[32mWe\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative \u001b[0m\n",
       "\u001b[32mpositions, since for any fixed offset k, P Epos+k can be represented as a linear function of\\nP Epos. We also \u001b[0m\n",
       "\u001b[32mexperimented with using learned positional embeddings \u001b[0m\u001b[32m[\u001b[0m\u001b[32m9\u001b[0m\u001b[32m]\u001b[0m\u001b[32m instead, and found that the two\\nversions produced nearly\u001b[0m\n",
       "\u001b[32midentical results \u001b[0m\u001b[32m(\u001b[0m\u001b[32msee Table 3 row \u001b[0m\u001b[32m(\u001b[0m\u001b[32mE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'page'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "            \u001b[32m'author'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "            \u001b[32m'source'\u001b[0m: \n",
       "\u001b[32m'/Users/loki/Documents/work/Personal/learnings/rag-cookbook-langchain/techniques/retriever/aiaun.pdf'\u001b[0m,\n",
       "            \u001b[32m'creator'\u001b[0m: \u001b[32m'LaTeX with hyperref'\u001b[0m,\n",
       "            \u001b[32m'moddate'\u001b[0m: \u001b[32m'2024-04-10T21:11:43+00:00'\u001b[0m,\n",
       "            \u001b[32m'subject'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "            \u001b[32m'trapped'\u001b[0m: \u001b[32m'/False'\u001b[0m,\n",
       "            \u001b[32m'keywords'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "            \u001b[32m'producer'\u001b[0m: \u001b[32m'pdfTeX-1.40.25'\u001b[0m,\n",
       "            \u001b[32m'page_label'\u001b[0m: \u001b[32m'3'\u001b[0m,\n",
       "            \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m15\u001b[0m,\n",
       "            \u001b[32m'creationdate'\u001b[0m: \u001b[32m'2024-04-10T21:11:43+00:00'\u001b[0m,\n",
       "            \u001b[32m'ptex.fullbanner'\u001b[0m: \u001b[32m'This is pdfTeX, Version 3.141592653-2.6-1.40.25 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mTeX Live 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m kpathsea version \u001b[0m\n",
       "\u001b[32m6.3.5'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'The first is a multi-head self-attention mechanism, and the second is a simple, \u001b[0m\n",
       "\u001b[32mposition-\\nwise fully connected feed-forward network. We employ a residual connection \u001b[0m\u001b[32m[\u001b[0m\u001b[32m11\u001b[0m\u001b[32m]\u001b[0m\u001b[32m around each of\\nthe two \u001b[0m\n",
       "\u001b[32msub-layers, followed by layer normalization \u001b[0m\u001b[32m[\u001b[0m\u001b[32m 1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from index_pipeline import vector_store, chunks\n",
    "from rich import print\n",
    "\n",
    "vector_retriever = vector_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "vector_result = vector_retriever.invoke(\"Why does self-attention have an advantage over recurrent layers in terms of parallelization and path length for long-range dependencies?\")\n",
    "\n",
    "print(vector_result[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://leerob.com/agents'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'AI Agents | Lee Robinson'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I teach developers how to build the future.'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'And they can\\'t take 10 minutes to run. You want typed languages and even linters (I </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">begrudgingly accept them now). This way the autonomous agents can \"self heal\" and fix their own mistakes. I </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sometimes fire off a prompt to Claude Code and see along the way, it fixed 2 or 3 issues from TypeScript / tests. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">It\\'s worth really internalizing this point and thinking about how it will impact your tooling choices in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">future. Claude Code still feels expensive, but relative to the value and time saved, it\\'s likely worth it for many</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">people (again, your mileage may vary). I want to try out some others: OpenCode, Amp, and a few other ones hitting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the market soon. v0 (Web Agent)\\nI\\'ve been using v0 for the longest since it\\'s built at Vercel. The first version</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(cough a v0) was pretty basic, and the models at the time really weren\\'t that great (1.5 years ago). But v0 has </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">gotten dramatically better since then. At some point, probably 6 months ago or so, it crossed a threshold where </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quality started to become really good. It wasn\\'t one specific thing, but many small things. The underlying model² </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(a preprocessing / classification step, a regularly updated base model like Claude 4, and a custom trained AutoFix </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model) helps fix errors other base models would hit generating code, plus it\\'s able to weave in user preference </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">data and general knowledge of web tools like Next.js / React / etc. I started using v0 for prototyping and making </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">nice UIs. Then I expanded to do animations like framer-motion. And now I\\'m doing full-stack, backend code on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Next.js side (APIs, talking to databases, etc). Still, I previously would hit a point where I needed to eject v0 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and go to Cursor. Which sucked because then my time in v0 was basically done, and the models in Cursor wouldn\\'t be</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as good at web stuff as v0. But now both of those are fixed. I can use the v0 model inside of Cursor, and v0 now </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">has two-way git sync. This means that I can push commits locally in Cursor, go back to the v0 UI, and it just </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">automatically pulls in the latest code and keeps on cooking. This is huge because now I can use Cursor and v0 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">together without it feeling like a duct-tape mess. Browser-based Agents\\nMy exploration here is still in progress. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The Claude Code GitHub integration didn\\'t work when I tried it first, and haven\\'t revisited since, so have been </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">really only using it locally. I have been using OpenAI Codex a bit more on some of my side projects, essentially as</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">yet another agent that can run in the background (in parallel). For example, I\\'ve asked it to think critically </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">about the app architecture and suggest alternative approaches. Or ask it to explain how it thinks the code works, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and then compare that to reality. Or even just say \"are there any obvious bugs or red flags\". It\\'s like a swarm </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(hehe) or people working for me. I\\'m using Devin at Vercel to merge a ton of small PRs to our docs³. Those things </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that die off in a Slack thread somewhere, or die in a Linear backlog. I just @ mention Devin in the thread, it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">makes the PR, and then we ship it. Funny enough, we also built a custom lil\\' GitHub Action which uses the AI SDK </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to have an \"AI code reviewer\". This then checks the output and suggests improvements.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://leerob.com/agents'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'AI Agents | Lee Robinson'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I teach developers how to build the future.'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"More agents in the loop. I haven't tried CodeRabbit but similar idea there. My recommendation</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to you all is: try out new tools, revisit old workflows. Things have likely gotten much better since you last </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tried. The state of the art will be redefined again in 6 months, and we'll have to start this over again.\"</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://leerob.com/agents'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'AI Agents | Lee Robinson'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I teach developers how to build the future.'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Let\\'s talk through each tool. Cursor (Primary IDE)\\nI\\'ve been using Cursor as my primary </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">IDE for about 4 months. Before that, I spent 6 months¹ flipping between Zed and Neovim (after using VS Code for a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">long time). Cursor is really good. For me, Cursor brings the familiarity of VS Code with the best AI interface for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">general programming (reading files, quick edits, tab completion). Sounds silly but the built-in git diff of VS Code</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is incredible and I prefer it over many other tools. I\\'ve only started to briefly experiment with background </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents, because at about the same time I started trying out Claude Code. Cursor seems to keep getting better on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">every release, so I\\'m going to stick with it. Claude Code (Agentic Loops)\\nClaude Code is the first CLI agent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">I\\'ve been extensively testing. There are others in the space (including OSS versions) which likely have similar </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">properties, so it\\'s too soon for me to say one is dramatically better than others. But more than anything, Claude </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Code has shown me the power of extremely fast loops with agents. It feels a bit faster than Cursor\\'s agent, but </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">this could also be the UX (it\\'s really well designed). Claude Code has access to a bunch of tools, including web </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">search, and is able to spin up subtasks to do even more work in parallel. In practice, I\\'ve found it to be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">extremely good when you can control the entire \"loop\". Write some code, check if it compiles, if not fix it. Then </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">try the tests. If they fail, fix it. Rinse and repeat for linting or other steps. This is where Software 1.0 best </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">practices meet Software 2.0 (AI-era). Having deterministic, fast ways to verify correctness in your apps is key for</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents. You want tests.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://leerob.com/agents'\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'AI Agents | Lee Robinson'\u001b[0m,\n",
       "            \u001b[32m'description'\u001b[0m: \u001b[32m'I teach developers how to build the future.'\u001b[0m,\n",
       "            \u001b[32m'language'\u001b[0m: \u001b[32m'en'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'And they can\\'t take 10 minutes to run. You want typed languages and even linters \u001b[0m\u001b[32m(\u001b[0m\u001b[32mI \u001b[0m\n",
       "\u001b[32mbegrudgingly accept them now\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. This way the autonomous agents can \"self heal\" and fix their own mistakes. I \u001b[0m\n",
       "\u001b[32msometimes fire off a prompt to Claude Code and see along the way, it fixed 2 or 3 issues from TypeScript / tests. \u001b[0m\n",
       "\u001b[32mIt\\'s worth really internalizing this point and thinking about how it will impact your tooling choices in the \u001b[0m\n",
       "\u001b[32mfuture. Claude Code still feels expensive, but relative to the value and time saved, it\\'s likely worth it for many\u001b[0m\n",
       "\u001b[32mpeople \u001b[0m\u001b[32m(\u001b[0m\u001b[32magain, your mileage may vary\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. I want to try out some others: OpenCode, Amp, and a few other ones hitting \u001b[0m\n",
       "\u001b[32mthe market soon. v0 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mWeb Agent\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nI\\'ve been using v0 for the longest since it\\'s built at Vercel. The first version\u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mcough a v0\u001b[0m\u001b[32m)\u001b[0m\u001b[32m was pretty basic, and the models at the time really weren\\'t that great \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1.5 years ago\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. But v0 has \u001b[0m\n",
       "\u001b[32mgotten dramatically better since then. At some point, probably 6 months ago or so, it crossed a threshold where \u001b[0m\n",
       "\u001b[32mquality started to become really good. It wasn\\'t one specific thing, but many small things. The underlying model² \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32ma preprocessing / classification step, a regularly updated base model like Claude 4, and a custom trained AutoFix \u001b[0m\n",
       "\u001b[32mmodel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m helps fix errors other base models would hit generating code, plus it\\'s able to weave in user preference \u001b[0m\n",
       "\u001b[32mdata and general knowledge of web tools like Next.js / React / etc. I started using v0 for prototyping and making \u001b[0m\n",
       "\u001b[32mnice UIs. Then I expanded to do animations like framer-motion. And now I\\'m doing full-stack, backend code on the \u001b[0m\n",
       "\u001b[32mNext.js side \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAPIs, talking to databases, etc\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Still, I previously would hit a point where I needed to eject v0 \u001b[0m\n",
       "\u001b[32mand go to Cursor. Which sucked because then my time in v0 was basically done, and the models in Cursor wouldn\\'t be\u001b[0m\n",
       "\u001b[32mas good at web stuff as v0. But now both of those are fixed. I can use the v0 model inside of Cursor, and v0 now \u001b[0m\n",
       "\u001b[32mhas two-way git sync. This means that I can push commits locally in Cursor, go back to the v0 UI, and it just \u001b[0m\n",
       "\u001b[32mautomatically pulls in the latest code and keeps on cooking. This is huge because now I can use Cursor and v0 \u001b[0m\n",
       "\u001b[32mtogether without it feeling like a duct-tape mess. Browser-based Agents\\nMy exploration here is still in progress. \u001b[0m\n",
       "\u001b[32mThe Claude Code GitHub integration didn\\'t work when I tried it first, and haven\\'t revisited since, so have been \u001b[0m\n",
       "\u001b[32mreally only using it locally. I have been using OpenAI Codex a bit more on some of my side projects, essentially as\u001b[0m\n",
       "\u001b[32myet another agent that can run in the background \u001b[0m\u001b[32m(\u001b[0m\u001b[32min parallel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. For example, I\\'ve asked it to think critically \u001b[0m\n",
       "\u001b[32mabout the app architecture and suggest alternative approaches. Or ask it to explain how it thinks the code works, \u001b[0m\n",
       "\u001b[32mand then compare that to reality. Or even just say \"are there any obvious bugs or red flags\". It\\'s like a swarm \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mhehe\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or people working for me. I\\'m using Devin at Vercel to merge a ton of small PRs to our docs³. Those things \u001b[0m\n",
       "\u001b[32mthat die off in a Slack thread somewhere, or die in a Linear backlog. I just @ mention Devin in the thread, it \u001b[0m\n",
       "\u001b[32mmakes the PR, and then we ship it. Funny enough, we also built a custom lil\\' GitHub Action which uses the AI SDK \u001b[0m\n",
       "\u001b[32mto have an \"AI code reviewer\". This then checks the output and suggests improvements.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://leerob.com/agents'\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'AI Agents | Lee Robinson'\u001b[0m,\n",
       "            \u001b[32m'description'\u001b[0m: \u001b[32m'I teach developers how to build the future.'\u001b[0m,\n",
       "            \u001b[32m'language'\u001b[0m: \u001b[32m'en'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m\"More\u001b[0m\u001b[32m agents in the loop. I haven't tried CodeRabbit but similar idea there. My recommendation\u001b[0m\n",
       "\u001b[32mto you all is: try out new tools, revisit old workflows. Things have likely gotten much better since you last \u001b[0m\n",
       "\u001b[32mtried. The state of the art will be redefined again in 6 months, and we'll have to start this over again.\"\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://leerob.com/agents'\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'AI Agents | Lee Robinson'\u001b[0m,\n",
       "            \u001b[32m'description'\u001b[0m: \u001b[32m'I teach developers how to build the future.'\u001b[0m,\n",
       "            \u001b[32m'language'\u001b[0m: \u001b[32m'en'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Let\\'s talk through each tool. Cursor \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPrimary IDE\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nI\\'ve been using Cursor as my primary \u001b[0m\n",
       "\u001b[32mIDE for about 4 months. Before that, I spent 6 months¹ flipping between Zed and Neovim \u001b[0m\u001b[32m(\u001b[0m\u001b[32mafter using VS Code for a \u001b[0m\n",
       "\u001b[32mlong time\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Cursor is really good. For me, Cursor brings the familiarity of VS Code with the best AI interface for \u001b[0m\n",
       "\u001b[32mgeneral programming \u001b[0m\u001b[32m(\u001b[0m\u001b[32mreading files, quick edits, tab completion\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Sounds silly but the built-in git diff of VS Code\u001b[0m\n",
       "\u001b[32mis incredible and I prefer it over many other tools. I\\'ve only started to briefly experiment with background \u001b[0m\n",
       "\u001b[32magents, because at about the same time I started trying out Claude Code. Cursor seems to keep getting better on \u001b[0m\n",
       "\u001b[32mevery release, so I\\'m going to stick with it. Claude Code \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAgentic Loops\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nClaude Code is the first CLI agent \u001b[0m\n",
       "\u001b[32mI\\'ve been extensively testing. There are others in the space \u001b[0m\u001b[32m(\u001b[0m\u001b[32mincluding OSS versions\u001b[0m\u001b[32m)\u001b[0m\u001b[32m which likely have similar \u001b[0m\n",
       "\u001b[32mproperties, so it\\'s too soon for me to say one is dramatically better than others. But more than anything, Claude \u001b[0m\n",
       "\u001b[32mCode has shown me the power of extremely fast loops with agents. It feels a bit faster than Cursor\\'s agent, but \u001b[0m\n",
       "\u001b[32mthis could also be the UX \u001b[0m\u001b[32m(\u001b[0m\u001b[32mit\\'s really well designed\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Claude Code has access to a bunch of tools, including web \u001b[0m\n",
       "\u001b[32msearch, and is able to spin up subtasks to do even more work in parallel. In practice, I\\'ve found it to be \u001b[0m\n",
       "\u001b[32mextremely good when you can control the entire \"loop\". Write some code, check if it compiles, if not fix it. Then \u001b[0m\n",
       "\u001b[32mtry the tests. If they fail, fix it. Rinse and repeat for linting or other steps. This is where Software 1.0 best \u001b[0m\n",
       "\u001b[32mpractices meet Software 2.0 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAI-era\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Having deterministic, fast ways to verify correctness in your apps is key for\u001b[0m\n",
       "\u001b[32magents. You want tests.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from rich import print\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(chunks, k=10)\n",
    "bm25_result = bm25_retriever.invoke(\"Why does self-attention have an advantage over recurrent layers in terms of parallelization and path length for long-range dependencies?\")\n",
    "\n",
    "print(bm25_result[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m16\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "from rich import print\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[\n",
    "        vector_retriever,\n",
    "        bm25_retriever,\n",
    "    ], weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "ensemble_result = ensemble_retriever.invoke(\"Why does self-attention have an advantage over recurrent layers in terms of parallelization and path length for long-range dependencies?\")\n",
    "\n",
    "print(len(ensemble_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Self-attention has significant advantages over recurrent layers in terms of parallelization and path length for \n",
       "long-range dependencies due to its architectural design. \n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Parallelization**: Self-attention layers allow for a constant number of sequential operations to connect all \n",
       "positions in the input sequence, which means that they can process all elements of the sequence simultaneously. In \n",
       "contrast, recurrent layers require a linear number of sequential operations <span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">O</span><span style=\"font-weight: bold\">(</span>n<span style=\"font-weight: bold\">))</span>, where n is the sequence length.\n",
       "This inherent sequential nature of recurrent layers limits their ability to leverage parallel computation, \n",
       "especially as sequence lengths increase, making them less efficient for long sequences.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Path Length for Long-Range Dependencies**: The ability to learn long-range dependencies is crucial in many \n",
       "sequence transduction tasks. Self-attention provides a direct connection between all positions in the input \n",
       "sequence, resulting in a maximum path length of <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">O</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span> for any two positions. This means that signals can be \n",
       "transmitted between distant positions in the sequence without traversing through multiple intermediate steps. In \n",
       "contrast, recurrent layers have a maximum path length of <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">O</span><span style=\"font-weight: bold\">(</span>n<span style=\"font-weight: bold\">)</span>, which increases the difficulty of learning \n",
       "dependencies between distant positions due to the longer paths that signals must traverse.\n",
       "\n",
       "In summary, self-attention's architecture enables efficient parallel processing and shorter path lengths for \n",
       "long-range dependencies, making it more effective than recurrent layers for handling complex sequence tasks.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Self-attention has significant advantages over recurrent layers in terms of parallelization and path length for \n",
       "long-range dependencies due to its architectural design. \n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Parallelization**: Self-attention layers allow for a constant number of sequential operations to connect all \n",
       "positions in the input sequence, which means that they can process all elements of the sequence simultaneously. In \n",
       "contrast, recurrent layers require a linear number of sequential operations \u001b[1m(\u001b[0m\u001b[1;35mO\u001b[0m\u001b[1m(\u001b[0mn\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m, where n is the sequence length.\n",
       "This inherent sequential nature of recurrent layers limits their ability to leverage parallel computation, \n",
       "especially as sequence lengths increase, making them less efficient for long sequences.\n",
       "\n",
       "\u001b[1;36m2\u001b[0m. **Path Length for Long-Range Dependencies**: The ability to learn long-range dependencies is crucial in many \n",
       "sequence transduction tasks. Self-attention provides a direct connection between all positions in the input \n",
       "sequence, resulting in a maximum path length of \u001b[1;35mO\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m for any two positions. This means that signals can be \n",
       "transmitted between distant positions in the sequence without traversing through multiple intermediate steps. In \n",
       "contrast, recurrent layers have a maximum path length of \u001b[1;35mO\u001b[0m\u001b[1m(\u001b[0mn\u001b[1m)\u001b[0m, which increases the difficulty of learning \n",
       "dependencies between distant positions due to the longer paths that signals must traverse.\n",
       "\n",
       "In summary, self-attention's architecture enables efficient parallel processing and shorter path lengths for \n",
       "long-range dependencies, making it more effective than recurrent layers for handling complex sequence tasks.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from rich import print\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "response = chat_model.invoke(f\"You are an expert in the field of AI and you are given a question and a document. You need to answer the question based on the document. Here is the question: Why does self-attention have an advantage over recurrent layers in terms of parallelization and path length for long-range dependencies? Here is the document: {ensemble_result}\")\n",
    "\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
