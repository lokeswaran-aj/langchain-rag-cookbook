{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-openai python-dotenv rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "schema = {\n",
    "    \"title\": \"StepBackQueryRewriting\",\n",
    "    \"description\": \"Generate a broader and more general query\",\n",
    "    \"type\": \"object\", \n",
    "    \"properties\": {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Broader and more general query\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\").with_structured_output(schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: \\nYou are a helpful assistant that generates a broader and more general query related to an input question. \\n\\nThe goal is to generate a broader and more general query that can help the retriever retrieve more relevant documents. \\n\\nGenerate a broader and more general query related to: what is langchain?\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "step_back_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a helpful assistant that generates a broader and more general query related to an input question. \\n\n",
    "The goal is to generate a broader and more general query that can help the retriever retrieve more relevant documents. \\n\n",
    "Generate a broader and more general query related to: {question}\n",
    "\"\"\"\n",
    ")\n",
    "step_back_prompt.format(question=\"what is langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'what are techniques for optimizing information retrieval and document processing in programming </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">frameworks?'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'query'\u001b[0m: \u001b[32m'what are techniques for optimizing information retrieval and document processing in programming \u001b[0m\n",
       "\u001b[32mframeworks?'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "llm_chain = step_back_prompt | chat_model\n",
    "result = llm_chain.invoke({\"question\": \"how to rewrite a query into multiple sub-queries and retrieve relevant documents in parallel in langchain?\"})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
